{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPHpTNd_Ssq-"
      },
      "source": [
        "# LTSM\n",
        "\n",
        "based on https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dczkbG4SSsrV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "#!conda install --yes --prefix {sys.prefix} tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tTZs0CBvSsrn"
      },
      "outputs": [],
      "source": [
        "# load packages\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.utils import np_utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5wy6EFYgSsr4"
      },
      "outputs": [],
      "source": [
        "# load text and covert to lowercase\n",
        "filename = \"Bowie_10K.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hHPU9yhnSsr6"
      },
      "outputs": [],
      "source": [
        "# create mapping of unique chars to integers, and a reverse mapping\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wkc1xvReSssP",
        "outputId": "f89401bf-a26f-4ed8-83de-17d14b85254c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  293525\n",
            "Total Vocab (Different characters):  58\n",
            "Total Patterns:  293425\n"
          ]
        }
      ],
      "source": [
        "# summarize the loaded data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab (Different characters): \", n_vocab)\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "    seq_in = raw_text[i:i + seq_length]\n",
        "    seq_out = raw_text[i + seq_length]\n",
        "    dataX.append([char_to_int[char] for char in seq_in])\n",
        "    dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sZg9866XSssU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ddeS52R5SssW"
      },
      "outputs": [],
      "source": [
        "# define the LSTM model with Keras\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement3-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2otzkcdSssm",
        "outputId": "005995b9-8369-44a4-83b0-718134f10a11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 256)               264192    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 58)                14906     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 279,098\n",
            "Trainable params: 279,098\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nLqkXcEGSssp"
      },
      "outputs": [],
      "source": [
        "# ALERT: very computationally expensive!\n",
        "\n",
        "# fit the model\n",
        "#model.fit(X, y, epochs=100, batch_size=300, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tAcdKEwSSstO"
      },
      "outputs": [],
      "source": [
        "# pick a random seed\n",
        "# start = numpy.random.randint(0, len(dataX)-1)\n",
        "# pattern = dataX[start]\n",
        "# print(\"Seed:\")\n",
        "# print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# # generate characters\n",
        "# for i in range(1000):\n",
        "#     x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "#     x = x / float(n_vocab)\n",
        "#     prediction = model.predict(x, verbose=0)\n",
        "#     index = numpy.argmax(prediction)\n",
        "#     result = int_to_char[index]\n",
        "#     seq_in = [int_to_char[value] for value in pattern]\n",
        "#     sys.stdout.write(result)\n",
        "#     pattern.append(index)\n",
        "#     pattern = pattern[1:len(pattern)]\n",
        "# print(\"\\nDone.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7kPh2yQSstT",
        "outputId": "81f0f70d-c484-475a-8448-b91320cfeb83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed:\n",
            "\" lright\n",
            "hey babe, let's stay out tonight\n",
            "you like me and i like it all\n",
            "we like dancing and we look di \"\n",
            "---------\n",
            "rine you seee you rene mo soeee\n",
            "ie tou dane in the sayt ih the shadoes in the shrd\n",
            "bel toe day\n",
            "be hetee the saan genee lives oh hee tat sh the shreene ie the shanens thet so aeleee the seanes white the saas shet so the wondd of the shanen in the shre thit so are the woale oh the soaee in the saade whll the soaee she seeee thete the saate thet saee the saate thet so toe wayl io the saade whlt toede a lore thet sae wou dnd a lise io she soane i woul me toe day\n",
            "ae iere\n",
            "in the sayt\n",
            "thit soeyer the saater white the saas shet so the wondd of the shanen in the shre bel the saane ii the saad\n",
            "whine don the saadee whet so yhu wou'd bri the soeee in the wayl io the saade whll the soaee shet to toe day\n",
            "be ie the saad\n",
            "whine don the saade whlt soeyed the saadee white toene the saad\n",
            "whu seet den the wayl in the wayl\n",
            "io the saale whll the soaee shet to toe day\n",
            "be dnd the saadee shete the saate thet saee the saad\n",
            "whu seet den the wondd oe the soaee in the saade whll the soree shete the saeee thet so to\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "# define the LSTM model with Keras\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "# load the network weights\n",
        "filename = \"./weights-improvement3-10-2.0464.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "print(\"---------\")\n",
        "\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = numpy.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "print(\"\\nDone.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sDYzNtHSstX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc": {
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}